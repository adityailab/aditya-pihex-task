# ğŸ“˜ PiHex Structured Answering API

This FastAPI-based service answers questions based on a Markdown knowledge base and returns structured responses conforming to a strict JSON schema.

## ğŸš€ Features

- âœ… Embedding-based document retrieval
- ğŸ§  Answer generation using a local LLM (via Ollama)
- ğŸ“‚ Markdown knowledge base ingestion
- âœ… Strict schema validation (answer, category, confidence, sources)
- ğŸ³ Docker support

---

## ğŸ“¦ Requirements

- Python 3.12+
- [Ollama](https://ollama.com/) with a local LLM (e.g. `mistral`)
- pip / virtualenv / Docker (optional)

---

## ğŸ§ª Local Setup

```bash
# 1. Clone repo & navigate in
git clone <your-repo-url>
cd pihex-task

# 2. Create and activate a virtual environment
python -m venv venv
source venv/bin/activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run the app
uvicorn main:app --reload
```

Visit the interactive API at:  
ğŸ‘‰ [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ğŸ³ Run with Docker

```bash
# 1. Build the image
docker build -t pihex-api .

# 2. Run the container
docker run -p 8000:8000 pihex-api
```

---

## ğŸ“¥ API Usage

**Endpoint:** `POST /ask`  
**Body:**

```json
{
  "question": "How does PiHex handle PII?"
}
```

**Response:**
```json
{
  "answer": "...",
  "category": "...",
  "confidence": 0.9,
  "sources": [
    { "doc": "...", "snippet": "..." }
  ]
}
```

---

## ğŸ§ª Evaluation

```bash
python eval_runner.py
```

Runs questions from `eval_questions.jsonl` and compares output to expected criteria.

---